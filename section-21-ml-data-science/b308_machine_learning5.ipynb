{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning V\n",
    "\n",
    "We now have a function that, as developers, we can use throughout our code bases to receive inputs and predict. We can do things like predict NSFW images.\n",
    "\n",
    "But at the moment we don't have much data. We've only used a dataset that has 150 rows. In real life, to train a complicated model, we have millions of rows.\n",
    "\n",
    "This function that fits and runs the `knn.fit()` takes a long time, and most of the time we're running these types of operations on a GPU, sometimes in the cloud because we wouldn't be able to do it on a regular computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is very time consuming. We wouldn't want every user that submits a snake image to actually run this function. We call this model persistence.\n",
    "\n",
    "Next time we want to make a prediction, we want to save this model to a file and use that file for predictions.\n",
    "\n",
    "When we're on an iPhone and we're using a machine learning feature, it's not going to run and train a model which is already there on our phone. The idea of __model persistence__ employs __Scikit-Learn__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data  # our input data\n",
    "y = iris.target # our labels\n",
    "\n",
    "feature_names = iris.feature_names # column names (pre-defined)\n",
    "target_names = iris.target_names # target names (pre-defined)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data  # our input data\n",
    "y = iris.target # our labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 80% training and 20% test\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  ['versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "sample = [[3, 5, 4, 2], [2, 3, 5, 4]]\n",
    "predictions = knn.predict(sample)\n",
    "predict_species = [iris.target_names[p] for p in predictions]\n",
    "print(\"Predictions: \", predict_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stores the trained model in a binary file. If we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlbrain.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from joblib import dump, load\n",
    "joblib.dump(knn, 'mlbrain.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the `joblib` file created. Instead of our retraining the model in the future, we can say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 2, 1,\n",
       "       1, 2, 1, 2, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = joblib.load('mlbrain.joblib')\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we get our predictions. And if we copy our sample data, it still works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  ['versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('mlbrain.joblib')\n",
    "model.predict(X_test)\n",
    "sample = [[3, 5, 4, 2], [2, 3, 5, 4]]\n",
    "predictions = model.predict(sample)\n",
    "predict_species = [iris.target_names[p] for p in predictions]\n",
    "print(\"Predictions: \", predict_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to save our model so that we don't have to keep training it, since that takes a lot of computing power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66b6dfc241c8325d69ccfbaf588ee11e398b2b02082dd5e73e37f3a4fd18fba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
